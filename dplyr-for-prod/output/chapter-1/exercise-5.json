["<h1 class=\"reading\" id=\"the-dplyr-api-ecoystem\">the dplyr API ecoystem</h1>","<p>You will learn how to create and work with lazy tables in the context of <code>data.table</code> and the <code>dtplyr</code> package. These very same principles can be applied to other dplyr back-ends. There are many different backends that you can use with dplyr.</p>","<p>Among the most popular are:</p>","<ul>\n<li>\n<a href=\"https://dbplyr.tidyverse.org/reference/index.html#built-in-database-backends\"><code>{dbplyr}</code></a>: this covers <em>many</em> databases backends such as ODBC, PostgreSQL, MySQL, and many more.</li>\n<li>\n<a href=\"https://spark.posit.co/\"><code>{sparklyr}</code></a>: provides a dplyr, broom, and DBI interface to Apache Spark as well as ML libraries, structured streaming, kubernetes deployments and more.</li>\n<li>\n<a href=\"https://r.duckdb.org/\"><code>{duckdb}</code></a> &amp; <a href=\"https://duckdblabs.github.io/duckplyr/\"><code>{duckplyr}</code></a>: use the powerful DuckDB in memory database all from R</li>\n<li>\n<a href=\"https://arrow.apache.org/docs/r/\"><code>{arrow}</code></a>: work with massive datasets of parquet, or csv files using dplyr</li>\n<li>\n<a href=\"https://github.com/tidyverse/multidplyr/\"><code>{multidplyr}</code></a>: process data across multiple cores using dplyr</li>\n</ul>\n","<p>At the end of the course, we will provide recommendations about how you may walk through these different backends as you scale, or as your usecases change.</p>"]