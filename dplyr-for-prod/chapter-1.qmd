---
title: Introduction
description: |
    dplyr is more than just a syntax; it's a frontend UI for data analysis, allowing users to write data manipulation instructions that can be executed in various backends. The dplyr API ecosystem includes packages like dbplyr, multidplyr, and sparklyr, which enable execution of dplyr code in different environments.
---

# Preface {.reading}

 In this course, I wont teach you to use cool dplyr verbs or teach you about non-standard evaluation. I'm not really interested in it. Nor am I the best person to teach you that. 
 
 Rather, I want to show you dplyr is ready to be used in production as well as teach you how to think about scaling your work. 
 
 Barriers to scaling R in production is less often about technical capability, and more about having a conceptual undertanding of what to do an having a vague idea of what tools are out there. 
 
 In this chapter of the course, we wil lay the conceptual foundation of why dplyr is a perfect tool for productionizing your code

# Course structure {.reading}

- todo once it has been written

# dplyr's impact {.reading}

dplyr's impact on data science often goes under-recognized. It is known most often for its readable syntax and chainable expression. dplyr's undeniable ergonomics has led to impersonations and derivations across languages: from the many python implementations such as [`siuba`](https://github.com/machow/siuba), [`dplython`](https://pythonhosted.org/dplython/), [`redframes`](https://github.com/maxhumber/redframes), [`dfply`](https://github.com/kieferk/dfply),  and now the great [Ibis](https://ibis-project.org/) project—which, as you'll see, shares more than just syntax—and I'm sure many more. One can also see the influence of dplyr's syntax in [Polars](https://docs.pola.rs/), the powerful rust based dataframe library with navtive bindings to python and community provided bindings to R. The [`TidierData.jl`](https://tidierorg.github.io/TidierData.jl/latest/) library is a 100% Julia implementation that "stick[s] as closely to tidyverse syntax as possible."

They say that imitation is the highest form of flattery. But in this case, I think it also speaks to the impact made by dplyr and the broader tidyverse ecosystem. 

# dplyr as a frontend {.reading}

dplyr's syntax is undeniably influential because it is so easy to use an so influential.

More important than the R package "dplyr", is the philisophical concept it embodies. dplyr is an abstraction layer on top of your data. I want you to think of dplyr as a frontend UI for data analysis. Much like how applications will have a pretty frontend UI that is designed with the end users in mind, dplyr is designed with an unfaltering focus on ergonomics for data scientists. 

Most applications have two components: a "client" side and a "server" side. The UI is the "client" where users interact and the "server" is where computation happens. dplyr, is a client side tool. dplyr is a way of writing data manipulation instructions. These instructions are compiled and handled by a backend process that will execute your code for you.

dplyr's syntax can be used to build an execute massive queries with in Apache Spark & Databricks, Snowflake, Microsoft SQL Server, Amazon Redshift, as well as many other data bases. Or, it can be used to work with data bigger than memory with DuckDB or Apache Arrow. The choice of tool is yours. But with them, you will never have to leave dplyr.

The subsequent chapters will introduce you to working with lazy tables. 

# the dplyr API ecoystem {.reading}

You will learn how to create and work with lazy tables in the context of `data.table` and the `dtplyr` package. These very same principles can be applied to other dplyr back-ends. There are many different backends that you can use with dplyr. 

Among the most popular are: 

- [`{dbplyr}`](https://dbplyr.tidyverse.org/reference/index.html#built-in-database-backends): this covers _many_ databases backends such as ODBC, PostgreSQL, MySQL, and many more.
- [`{sparklyr}`](https://spark.posit.co/): provides a dplyr, broom, and DBI interface to Apache Spark as well as ML libraries, structured streaming, kubernetes deployments and more.
- [`{duckdb}`](https://r.duckdb.org/) & [`{duckplyr}`](https://duckdblabs.github.io/duckplyr/): use the powerful DuckDB in memory database all from R
- [`{arrow}`](https://arrow.apache.org/docs/r/): work with massive datasets of parquet, or csv files using dplyr
- [`{multidplyr}`](https://github.com/tidyverse/multidplyr/): process data across multiple cores using dplyr
    
At the end of the course, we will provide recommendations about how you may walk through these different backends as you scale, or as your usecases change. 
