title: "DuckDB Deep Dive"
author: "Josiah Parry"

project:
  type: book

book:
  chapters:
    - index.qmd
    - chapter1.qmd
    - chapter2.qmd
    - chapter3.qmd
    - chapter4.qmd
    - chapter5.qmd


description: |
  Since it was first announced in 2019, DuckDB has been revolutionizing what it means to be a database. DuckDB is a zero-dependency and in-process database designed specifically for analytics in mind. It is blazingly fast, efficient, and scalable. 

  In this course you will learn about what makes DuckDB unique compared to its competitors as well as how to harness the `{duckdb}` and `{duckplyr}` packages directly from R. 
  
  **Why should you use DuckDB?**

  - DuckDB can complete mid-scale data engineering workflows faster than a Databricks cluster can start up
  - It is free and open source helping you avoid vendor lock in
  - Can utilize Apache Arrow for fast and low-cost data transfer between processes
  - WASM compatible and can be used in browser-only applications 
  - Speed up Shiny applications
  - much much more

outcomes:
  - Understand DuckDB's role in edge compute
  - Analyze larger-than-memory datasets
  - Work with partitioned parquet datasets 
  - Scale analytics using dplyr and dbplyr
  - Create persistent databases using DuckDB's file format
  - Complete starter project to use DuckDB in a Shiny app
  - Comes with all source code and files


summary: |
  DuckDB is a fast, zero-dependency, in-process database made for data scientists. Lean on DuckDB's tight R integration to scale to larger-than-memory workloads.

categories: 
  - database
  - production
  - duckdb


# theme: none
# highlight-style: none
eval: false
# embed-resources: true

# project:
#   post-render:
#     - parser.R