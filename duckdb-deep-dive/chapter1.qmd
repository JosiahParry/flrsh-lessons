---
title: Building a conceptual foundation 
summary: |
    In this chapter, you'll get to know what makes DuckDB powerful.

    DuckDB is the SQLite for analytics. Due to its zero-dependencies and portability, it is perfect for using in edge-compute, embedded in the browser, or super-charging your analytic workflows. This chapter is dedicated to providing you with the conceptual foundations to understand the wider big data ecosystem. We touch on OLAP, edge devices, vectorized compute, Apache Arrow, and row-vs columnar storage. 
---

# Why should you care about DuckDB? {.reading}

DuckDB is an **online analytical processing** (OLAP) database. OLAP, a term you may start seeing more of in the future, is a different take on databases. Traditionally, databases have been focused on _transactional_ data. The OLAP approach is focused on _answering questions_ from your data rather than acting on things such as a transaction. Because of this focus, the database is designed differently as you will see later. 


## Self-contained

One of DuckDB's defining features is that it is zero-dependency and entirely embedded. This means that DuckDB can be installed just about anywhere without additional database management system (DBMS) software. Being _embedded_ means that DuckDB is integrated
into the applications that use it making them able to store, retrieve, and manipulate data without needing a separate database server process. This results in lightning fast data transfer into and out of the database. 

Traditional databases are designed to scale outwards across multiple nodes (machines). In contrast, DuckDB is designed as a single node database

{{ TODO single node / embedded vs multi-node image }}

## Edge compute

This portability lends itself to use for **edge computing**. The idea behind edge computing is that data processing can happen closer to where it is needed. You'll often hear of **edge devices** these are things like sensor or other small devices. Traditionally these devices would collect data, sending it off to a server for processing and then await for a response.

{{ TODO placeholder edge compute image }}

Due to DuckDB's relatively small installation size, portability and memory efficiency, much of the necessary computation can happen directly on these devices. For example, DuckDB is compatible with **WebAssembly** (WASM) meaning that it can be used directly in the browser without having to have any additional software installed. This can be a massive advantage when coupled with tools like [`{webr}`](https://webr.r-wasm.org/) and [`{shinylive}`](https://posit-dev.github.io/r-shinylive/).


# Why is duckdb so powerful? {.reading}

R is **vectorized** by default. Rather than operating on a single value at a time, a _vectorized_ operation is done on many values _at the same time_. 

DuckDB sets itself apart from traditional databases such as PostgreSQL and SQLite by being vectorized—just like R. DuckDB processes chunks of data simultaneously as opposed to single rows like is typically done. So instead of processing 1 row at a time, DuckDB can process, for example, 1000 rows! This is part of what gives DuckDB its impressive performance. 

DuckDB uses what is called a **columnar** storage. In traditional databases, data is stored at the record level. Each record is taken as a whole, then the columns that aren't needed are discarded. In an analytical workflow, this is really inefficient. Because more often or not, you don't care about every single column all at the same time. 

Much of the work that you do involves aggregating single variables, or operations involving one or two columns. Think about the many dplyr pipelines you may have made, these are always (with the exception of [`rowwise()`](https://dplyr.tidyverse.org/articles/rowwise.html)) done in a column-oriented manner—selecting columns, creating or modifying them, mapping across them using [`across()`](https://dplyr.tidyverse.org/reference/across.html).

Columnar storage is much like a data.frame. Data is stored in columns as opposed to each row like in traditional databases. Since each column can be millions, if not billions, of records, these columns are stored in chunks as well. With this approach, if we're performing operations using only two columns—e.g. `price` and `population`—we can completely ignore every other column in the databases and only work with what we need. This saves us precious compute resources. 

DuckDB's "columnar-vectorized query execution engine" makes it ideal to work with columnar storage such as parquet. 

## Arrow integration

We won't dive into Apache Arrow now, but it is important for you to understand, generally, what it is and why it is so powerful. 

Apache Arrow is not actually a piece of software. At its core, Apache Arrow is a specficiation (TODO hyperlink) that describes how columnar data should be represented in memory. Many languages have support for Arrow through package or libraries including R's [`{arrow}`](https://arrow.apache.org/docs/r/) package. 

{{ TODO image here }}

Because Arrow specifies what an array should look like at the lowest level, any tool that knows what Arrow an array looks like can use it. With Arrow, data can be used by multiple tools and processes without having to write out to an intermediary place. Arrow data needing to restructure it. This allows anything that uses arrow to be able to use the same data regardless of laguage without copying the underlying data!

DuckDB's vectorized layout is quite similar to Apache Arrow. So supporting Arrow requires little overhead for DuckDB. As a result, DuckDB has a very strong Arrow integration. This means that in R you can combine DuckDB, {arrow}, [`{polars}`](https://pola-rs.github.io/r-polars/), and even hand the data over to another tool such as [DataFusion](https://datafusion.apache.org/) in Rust or [`pyarrow`](https://arrow.apache.org/docs/python/index.html) in python without having to write it out or copy it! 

By not duplicating the data we save a bunch of computing time and memory space.  

<!-- TODO https://pola-rs.github.io/r-polars/man/as_polars_df.html -->


## DuckDB in the R ecosystem

DuckDB exists in the R ecosystem as two packages. [`{duckdb}`](https://r.duckdb.org/) and [`{duckplyr}`](https://duckdblabs.github.io/duckplyr/)

Two packages: duckdb and duckplyr

